{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSDA3VEJR3o9"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import string\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-BJ0ti_SGNS"
      },
      "outputs": [],
      "source": [
        "#Hyper Params Do Not Change\n",
        "\n",
        "PAD_INDEX = 0\n",
        "UNK_INDEX = 1\n",
        "PAD_TOKEN = '<pad>'\n",
        "UNK_TOKEN = '<unk>'\n",
        "MAX_LENGTH = 256\n",
        "BATCH_SIZE = 1\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 12\n",
        "N_LAYERS = 3\n",
        "DROPOUT_RATE = 0.1\n",
        "LR = 3e-4\n",
        "N_EPOCHS = 5\n",
        "\n",
        "UNIVERSAL_TAGS = [\n",
        "    \"VERB\",\n",
        "    \"NOUN\",\n",
        "    \"PRON\",\n",
        "    \"ADJ\",\n",
        "    \"ADV\",\n",
        "    \"ADP\",\n",
        "    \"CONJ\",\n",
        "    \"DET\",\n",
        "    \"NUM\",\n",
        "    \"PRT\",\n",
        "    \"X\",\n",
        "    \".\",\n",
        "]\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nF3IUS0o104R"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Tokenizer:\n",
        "    \n",
        "    def __init__(self):\n",
        "        \n",
        "        self.vocab = {}\n",
        "        self.tags = {w:i for i, w in enumerate(UNIVERSAL_TAGS)}\n",
        "        \n",
        "    def train(self, corpus):\n",
        "        vocab = {}\n",
        "        counter = 2\n",
        "        for sentence in tqdm(corpus, desc='Constructing Embeddings', file=sys.stdout):\n",
        "            for word in sentence:\n",
        "                if word not in vocab:\n",
        "                    vocab[word] = counter\n",
        "                    counter += 1\n",
        "                    \n",
        "        vocab[PAD_TOKEN] = PAD_INDEX\n",
        "        vocab[UNK_TOKEN] = UNK_INDEX\n",
        "        self.vocab = vocab\n",
        "        \n",
        "    def tokenize(self, sentence):\n",
        "        tokens = []\n",
        "        for word in sentence:\n",
        "            if word in self.vocab:\n",
        "                tokens.append(self.vocab[word])\n",
        "            else:\n",
        "                tokens.append(self.vocab[UNK_TOKEN])\n",
        "        return tokens\n",
        "    \n",
        "    def tag(self, tag):\n",
        "        if tag not in self.tags:\n",
        "            return 'X'\n",
        "        return self.tags[tag]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUEhuLHMSH-M"
      },
      "outputs": [],
      "source": [
        "class TaggedDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, x, y, tokenizer, max_length):\n",
        "        \n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        tags = self.y[index]\n",
        "        sentence = self.x[index]\n",
        "        tokens = self.tokenizer.tokenize(sentence)\n",
        "        if len(tokens) > self.max_length:\n",
        "          tokens = tokens[:256]\n",
        "          length = 256\n",
        "        else:\n",
        "          length = len(tokens)\n",
        "        labels = []\n",
        "        for i in range(length):\n",
        "            tag = tags[i]\n",
        "            label = self.tokenizer.tag(tag)\n",
        "            labels.append(label)\n",
        "        ret = {\"ids\" : tokens,\n",
        "               \"label\" : labels}\n",
        "        return ret\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "def collate(batch, pad_index):\n",
        "    \n",
        "    batch_ids = [torch.LongTensor(i['ids']) for i in batch]\n",
        "    batch_ids = nn.utils.rnn.pad_sequence(batch_ids, padding_value=pad_index, batch_first=True)\n",
        "    batch_label = torch.LongTensor([i['label'] for i in batch])\n",
        "    batch = {'ids': batch_ids, 'label': batch_label}\n",
        "    return batch\n",
        "\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxq8CRxBSRKR"
      },
      "outputs": [],
      "source": [
        "class BiLSTMTagger(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout_rate, pad_index):\n",
        "        \n",
        "        super(BiLSTMTagger, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_index)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(2*hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        \n",
        "        \n",
        "    def forward(self, ids):\n",
        "        \n",
        "        embeddings = self.embedding(ids)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        out, _= self.lstm(embeddings)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy3-vIaUSjLv"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    \n",
        "    @staticmethod\n",
        "    def train(dataloader, model, criterion, optimizer, device):\n",
        "        model.train()\n",
        "        epoch_losses = []\n",
        "        epoch_accs = []\n",
        "\n",
        "        for batch in tqdm(dataloader, desc='Training', file=sys.stdout):\n",
        "            ids = batch['ids'].to(device)\n",
        "            label = batch['label'].to(device)\n",
        "            label = label.squeeze(dim=0)\n",
        "            prediction = model(ids).squeeze(dim=0)\n",
        "            loss = criterion(prediction, label)\n",
        "            accuracy = Trainer.get_accuracy(prediction, label)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_losses.append(loss.item())\n",
        "            epoch_accs.append(accuracy.item())\n",
        "\n",
        "        return epoch_losses, epoch_accs\n",
        "    \n",
        "    @staticmethod\n",
        "    def evaluate(dataloader, model, criterion, device):\n",
        "        model.eval()\n",
        "        epoch_losses = []\n",
        "        epoch_accs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(dataloader, desc='Evaluating', file=sys.stdout):\n",
        "                ids = batch['ids'].to(device)\n",
        "                label = batch['label'].to(device)\n",
        "                label = label.squeeze(dim=0)\n",
        "                prediction = model(ids).squeeze(dim=0)\n",
        "                loss = criterion(prediction, label)\n",
        "                accuracy = Trainer.get_accuracy(prediction, label)\n",
        "                epoch_losses.append(loss.item())\n",
        "                epoch_accs.append(accuracy.item())\n",
        "\n",
        "        return epoch_losses, epoch_accs\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_accuracy(prediction, label):\n",
        "        size, _ = prediction.shape\n",
        "        predicted_classes = prediction.argmax(dim=-1)\n",
        "        correct_predictions = predicted_classes.eq(label).sum()\n",
        "        return correct_predictions / size\n",
        "\n",
        "    @staticmethod\n",
        "    def count_parameters(model):\n",
        "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    def predict_sentiment(text, model, tokenizer, device):\n",
        "        tokens = tokenizer.tokenize(text)\n",
        "        tensor = torch.LongTensor(tokens).unsqueeze(dim=0).to(device)\n",
        "        prediction = model(tensor).squeeze(dim=0)\n",
        "        probability = torch.softmax(prediction, dim=-1)\n",
        "        predicted_class = probability.argmax(dim=-1).to('cpu').numpy()\n",
        "        predicted_probability = []\n",
        "        for i in range(len(tokens)):\n",
        "            c = predicted_class[i]\n",
        "            predicted_probability.append(probability[i][c].item())\n",
        "        predicted_probability = np.array(predicted_probability)\n",
        "        return predicted_class, predicted_probability\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDgLx1E82E6H"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_normal_(m.weight)\n",
        "        nn.init.zeros_(m.bias)\n",
        "    elif isinstance(m, nn.LSTM):\n",
        "        for name, param in m.named_parameters():\n",
        "            if 'bias' in name:\n",
        "                nn.init.zeros_(param)\n",
        "            elif 'weight' in name:\n",
        "                nn.init.orthogonal_(param)\n",
        "               \n",
        "def build_dataset(loc=\"\"):\n",
        "    \n",
        "    if loc == \"\":\n",
        "        data = nltk.corpus.brown.tagged_sents(tagset=\"universal\")\n",
        "    else: \n",
        "        with open(loc, 'r') as f:\n",
        "          data = json.load(f)\n",
        "          data = list(data.values())\n",
        "    \n",
        "    x = []\n",
        "    y = []\n",
        "    \n",
        "    for sentence in data:\n",
        "        words = []\n",
        "        tags = []\n",
        "        for word, tag in sentence:\n",
        "            words.append(word)\n",
        "            tags.append(tag)\n",
        "        x.append(words)\n",
        "        y.append(tags)\n",
        "        \n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m5XKJHK2PGF",
        "outputId": "e2eea97f-f5e2-4c8e-cf47-54c7dd1b44a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
            "Constructing Embeddings: 100%|██████████| 45872/45872 [00:00<00:00, 222236.60it/s]\n"
          ]
        }
      ],
      "source": [
        "#Data Processing\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "X, y = build_dataset()\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.train(X_train)\n",
        "\n",
        "train_data = TaggedDataset(X_train, y_train, tokenizer, MAX_LENGTH)\n",
        "valid_data = TaggedDataset(X_valid, y_valid, tokenizer, MAX_LENGTH)\n",
        "\n",
        "collate = functools.partial(collate, pad_index=PAD_INDEX)\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, collate_fn=collate, shuffle=True)\n",
        "valid_dataloader = torch.utils.data.DataLoader(valid_data, batch_size=BATCH_SIZE, collate_fn=collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH_VaXlc4CqT"
      },
      "outputs": [],
      "source": [
        "#Create Necessities for Training\n",
        "vocab_size = len(tokenizer.vocab)\n",
        "model = BiLSTMTagger(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, DROPOUT_RATE, PAD_INDEX)\n",
        "model.apply(initialize_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbR5UiNw4NS-",
        "outputId": "0e8d184b-07d3-4425-8a19-39dd3003e748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 45872/45872 [09:08<00:00, 83.65it/s]\n",
            "Evaluating: 100%|██████████| 11468/11468 [00:31<00:00, 358.38it/s]\n",
            "epoch: 1\n",
            "train_loss: 0.235, train_acc: 0.921\n",
            "valid_loss: 0.137, valid_acc: 0.955\n",
            "Training: 100%|██████████| 45872/45872 [09:10<00:00, 83.32it/s]\n",
            "Evaluating: 100%|██████████| 11468/11468 [00:32<00:00, 356.46it/s]\n",
            "epoch: 2\n",
            "train_loss: 0.100, train_acc: 0.968\n",
            "valid_loss: 0.102, valid_acc: 0.967\n",
            "Training: 100%|██████████| 45872/45872 [09:10<00:00, 83.34it/s]\n",
            "Evaluating: 100%|██████████| 11468/11468 [00:31<00:00, 360.40it/s]\n",
            "epoch: 3\n",
            "train_loss: 0.062, train_acc: 0.980\n",
            "valid_loss: 0.098, valid_acc: 0.970\n",
            "Training: 100%|██████████| 45872/45872 [09:10<00:00, 83.29it/s]\n",
            "Evaluating: 100%|██████████| 11468/11468 [00:31<00:00, 359.07it/s]\n",
            "epoch: 4\n",
            "train_loss: 0.042, train_acc: 0.986\n",
            "valid_loss: 0.108, valid_acc: 0.970\n",
            "Training: 100%|██████████| 45872/45872 [09:08<00:00, 83.61it/s]\n",
            "Evaluating: 100%|██████████| 11468/11468 [00:31<00:00, 361.57it/s]\n",
            "epoch: 5\n",
            "train_loss: 0.031, train_acc: 0.990\n",
            "valid_loss: 0.109, valid_acc: 0.971\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "best_valid_loss = float('inf')\n",
        "best_valid_acc = -1\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "\n",
        "epoch_to_train_losses = {}\n",
        "epoch_to_train_accs = {}\n",
        "epoch_to_valid_losses = {}\n",
        "epoch_to_valid_accs = {}\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss, train_acc = Trainer.train(train_dataloader, model, criterion, optimizer, device)\n",
        "    valid_loss, valid_acc = Trainer.evaluate(valid_dataloader, model, criterion, device)\n",
        "\n",
        "    train_losses.extend(train_loss)\n",
        "    train_accs.extend(train_acc)\n",
        "    valid_losses.extend(valid_loss)\n",
        "    valid_accs.extend(valid_acc)\n",
        "\n",
        "    epoch_to_train_losses[epoch] = train_loss\n",
        "    epoch_to_train_accs[epoch] = train_acc\n",
        "    epoch_to_valid_losses[epoch] = valid_loss\n",
        "    epoch_to_valid_accs[epoch] = valid_acc\n",
        "\n",
        "    epoch_train_loss = np.mean(train_loss)\n",
        "    epoch_train_acc = np.mean(train_acc)\n",
        "    epoch_valid_loss = np.mean(valid_loss)\n",
        "    epoch_valid_acc = np.mean(valid_acc)\n",
        "\n",
        "    # Save the model that achieves the smallest validation loss.\n",
        "    if epoch_valid_loss < best_valid_loss:\n",
        "        best_valid_loss = epoch_valid_loss\n",
        "        torch.save(model.state_dict(), 'valid_loss_lstm.pt')\n",
        "    \n",
        "    if epoch_valid_acc > best_valid_acc:\n",
        "        best_valid_acc = epoch_valid_acc\n",
        "        torch.save(model.state_dict(), 'valid_acc_lstm.pt')\n",
        "\n",
        "\n",
        "    print(f'epoch: {epoch+1}')\n",
        "    print(f'train_loss: {epoch_train_loss:.3f}, train_acc: {epoch_train_acc:.3f}')\n",
        "    print(f'valid_loss: {epoch_valid_loss:.3f}, valid_acc: {epoch_valid_acc:.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc3K_9gzcUCg"
      },
      "outputs": [],
      "source": [
        "epoch_to_train_losses = pd.DataFrame(epoch_to_train_losses)\n",
        "epoch_to_train_accs = pd.DataFrame(epoch_to_train_accs)\n",
        "epoch_to_valid_losses = pd.DataFrame(epoch_to_valid_losses)\n",
        "epoch_to_valid_accs = pd.DataFrame(epoch_to_valid_accs)\n",
        "\n",
        "epoch_to_train_losses.to_csv('epoch_to_train_losses.csv')\n",
        "epoch_to_train_accs.to_csv('epoch_to_train_accs.csv')\n",
        "epoch_to_valid_losses.to_csv('epoch_to_valid_losses.csv')\n",
        "epoch_to_valid_accs.to_csv('epoch_to_valid_accs.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "133uNFndjPam",
        "outputId": "cdb8a0e0-b4ec-4ecc-976c-cc00b557b446"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_560e84bb-eeb2-4289-a267-9037f1b63de6\", \"epoch_to_train_losses.csv\", 4992940)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_9bc96fae-89f5-49c8-97b2-00af1c532153\", \"epoch_to_train_accs.csv\", 2333931)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_5959320c-e91c-4dbf-bfc5-8158eb1cd498\", \"epoch_to_valid_losses.csv\", 1234585)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_827205d5-8169-41ff-9b65-e71e280fe3e8\", \"epoch_to_valid_accs.csv\", 615429)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_061a9e29-eddc-4258-9d07-b9d5b6f78ea8\", \"valid_loss_lstm.pt\", 68588063)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_d32162e5-8add-4fb7-adc9-f2a3756a92b2\", \"valid_acc_lstm.pt\", 68588063)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('epoch_to_train_losses.csv')\n",
        "files.download('epoch_to_train_accs.csv')\n",
        "files.download('epoch_to_valid_losses.csv')\n",
        "files.download('epoch_to_valid_accs.csv')\n",
        "files.download('valid_loss_lstm.pt')\n",
        "files.download('valid_acc_lstm.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
